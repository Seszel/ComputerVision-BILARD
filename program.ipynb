{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Śledzenie rozgyrwki bilarda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import niezbędnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "# import PIL\n",
    "# import os\n",
    "# import sys\n",
    "# import glob\n",
    "# import random\n",
    "\n",
    "# from pprint import pprint\n",
    "from ipywidgets import Video\n",
    "\n",
    "import PIL\n",
    "from IPython.display import display\n",
    "# from PIL.ExifTags import TAGS\n",
    "\n",
    "def imshow(a):\n",
    "  a = a.clip(0, 255).astype('uint8')\n",
    "  if a.ndim == 3:\n",
    "    if a.shape[2] == 4:\n",
    "      a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "    else:\n",
    "      a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "  display(PIL.Image.fromarray(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza wideo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie wideo i jego podstawowych właściwości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie loaded :)\n",
      "Wysokość i szerokość obrazu: 1054 x 1924\n",
      "Liczba klatek na sekundę: 59.891696750902526\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture('data/9-ball/video6.mov')\n",
    "if video.isOpened():\n",
    "    print('Movie loaded :)')\n",
    "\n",
    "width = int(video.get(3))\n",
    "height = int(video.get(4))\n",
    "print(f'Wysokość i szerokość obrazu: {height} x {width}')\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(f'Liczba klatek na sekundę: {fps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyświetlenie analizowanego wideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6e4a59836144ddbec530a04491b14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00\\x14ftypqt  \\x00\\x00\\x00\\x00qt  \\x00\\x00\\x00\\x08wide\\x01\\x02\\xee\\xc3mdat\\x00\\x01\\x03…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Video.from_file('data/9-ball/video1.mov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oddzielenie tła od ruszających się obiektów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_foreground_knn = cv2.VideoWriter('foreground_knn.avi', cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height), 0)\n",
    "video_foreground_mog2 = cv2.VideoWriter('foreground_mog2.avi', cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height), 0)\n",
    "\n",
    "foreground_knn = cv2.createBackgroundSubtractorKNN()\n",
    "foreground_mog2 = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "while video.isOpened():\n",
    "  ret, frame = video.read()\n",
    "\n",
    "  if ret:\n",
    "    video_foreground_knn.write(foreground_knn.apply(frame))\n",
    "    video_foreground_mog2.write(foreground_mog2.apply(frame))\n",
    "  else:\n",
    "    break\n",
    "\n",
    "video_foreground_knn.release()\n",
    "video_foreground_mog2.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konwersja formatów wygenerowanych wideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -hide_banner -loglevel error -i foreground_knn.avi -y foreground_knn.mp4\n",
    "!ffmpeg -hide_banner -loglevel error -i foreground_mog2.avi -y foreground_mog2.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyświetlenie wyników działania algorytmów oddzielających tło od ruszających się obiektów (maskujących tło)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Algorytm cv2.createBackgroundSubtractorKNN()')\n",
    "Video.from_file('foreground_knn.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Algorytm cv2.createBackgroundSubtractorMOG2()')\n",
    "Video.from_file('foreground_mog2.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po analizie wyników działania powyższych algorytmów do dalszej pracy wybieram algorytm KNN, który osiągnął lepszy wynik od MOG2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poszukiwanie współrzędnych bil na filmie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as time\n",
    "video = cv2.VideoCapture('data/9-ball/video7.mov')\n",
    "circles = None\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Take each frame\n",
    "    _, frame = video.read()\n",
    "\n",
    "    # If video ends then break\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    blur = cv2.medianBlur(frame,5)\n",
    "    cimg = cv2.cvtColor(blur,cv2.COLOR_BGR2GRAY)\n",
    "    circles = cv2.HoughCircles(cimg,cv2.HOUGH_GRADIENT,1,20,\n",
    "                            param1=60,param2=20,minRadius=13,maxRadius=22)\n",
    "\n",
    "    circles = np.uint16(np.around(circles))\n",
    "\n",
    "    \n",
    "\n",
    "    for i in circles[0,:]:\n",
    "        # draw the outer circle\n",
    "        cv2.circle(frame,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "        # draw the center of the circle\n",
    "        cv2.circle(frame,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykorzystanie algorytmu CSRT do śledzenia znalezionych bili na filmie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tracker(tracker_type):\n",
    "  tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "\n",
    "  if tracker_type == 'BOOSTING':\n",
    "      return cv2.legacy.TrackerBoosting_create()\n",
    "  if tracker_type == 'MIL':\n",
    "      return cv2.legacy.TrackerMIL_create()\n",
    "  if tracker_type == 'KCF':\n",
    "      return cv2.legacy.TrackerKCF_create()\n",
    "  if tracker_type == 'TLD':\n",
    "      return cv2.legacy.TrackerTLD_create()\n",
    "  if tracker_type == 'MEDIANFLOW':\n",
    "      return cv2.legacy.TrackerMedianFlow_create()\n",
    "  if tracker_type == 'GOTURN':\n",
    "      return cv2.TrackerGOTURN_create()\n",
    "  if tracker_type == 'MOSSE':\n",
    "      return cv2.legacy.TrackerMOSSE_create()\n",
    "  if tracker_type == \"CSRT\":\n",
    "      return cv2.TrackerCSRT_create()\n",
    "\n",
    "def draw_bbox(frame, bbox, color=(255, 255, 255)):\n",
    "  p1 = (int(bbox[0]), int(bbox[1]))\n",
    "  p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "  cv2.rectangle(frame, p1, p2, color, 2, 1)\n",
    "\n",
    "def circle_to_rectangle(circle):\n",
    "    return (int(circle[0]-circle[2]-5), int(circle[1]-circle[2]-5), int(2*circle[2]+10),  int(2*circle[2]+10))\n",
    "\n",
    "def collision(c1, c2):\n",
    "    if (abs(c1[0] - c2[0])) < 30 and (abs(c1[1] - c2[1])) < 30:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def count_distance(b1, b2):\n",
    "    centroid1 = ((b1[0] + b1[2])/2, (b1[1] + b1[3])/2)\n",
    "    centroid2 = ((b2[0] + b2[2])/2, (b2[1] + b2[3])/2) \n",
    "    clash = collision(centroid1, centroid2)\n",
    "    if clash:\n",
    "        x = (centroid1[0] + centroid2[0])/2\n",
    "        y = (centroid1[1] + centroid2[1])/2\n",
    "        return (int(x), int(y))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie loaded :)\n",
      "Wysokość i szerokość obrazu: 1172 x 2144\n",
      "Liczba klatek na sekundę: 59.21052631578947\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture('data/9-ball/video1.mov')\n",
    "if video.isOpened():\n",
    "    print('Movie loaded :)')\n",
    "\n",
    "width = int(video.get(3))\n",
    "height = int(video.get(4))\n",
    "print(f'Wysokość i szerokość obrazu: {height} x {width}')\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(f'Liczba klatek na sekundę: {fps}')\n",
    "\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "ret, frame = video.read()\n",
    "\n",
    "# color = ('b','g','r')\n",
    "# for i,col in enumerate(color):\n",
    "#     histr = cv2.calcHist([frame],[i],None,[256],[0,256])\n",
    "#     plt.plot(histr,color = col)\n",
    "#     plt.xlim([0,256])\n",
    "# plt.show()\n",
    "\n",
    "# histr = cv2.calcHist([frame],[0],None,[256],[0,256])\n",
    "# plt.plot(histr)\n",
    "# plt.show()\n",
    "# print(np.argmax(histr))\n",
    "\n",
    "\n",
    "\n",
    "filter = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "sharpen_img_1=cv2.filter2D(frame,-1,filter)\n",
    "# imshow(sharpen_img_1)\n",
    "\n",
    "cimg = cv2.cvtColor(sharpen_img_1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "circles = cv2.HoughCircles(cimg,cv2.HOUGH_GRADIENT,1,20,\n",
    "                            param1=60,param2=20,minRadius=13,maxRadius=22)\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "bills = []\n",
    "count = 0\n",
    "for c in circles[0]:\n",
    "  bills.append(create_tracker('CSRT'))\n",
    "  bills[-1].init(frame, circle_to_rectangle(c))\n",
    "  # count += 1\n",
    "\n",
    "# print(count)\n",
    "\n",
    "for i in circles[0,:]:\n",
    "  # draw the outer circle\n",
    "  cv2.circle(frame,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "  # draw the center of the circle\n",
    "  cv2.circle(frame,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "# imshow(frame)\n",
    "\n",
    "# frames_track = np.zeros((len(bills)))\n",
    "# frames_number = 0\n",
    "# print(frames_track)\n",
    "video_tracker = cv2.VideoWriter('video_tracker.avi', cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height))\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    # frames_number += 1\n",
    "\n",
    "    if ret:\n",
    "      bboxes = []\n",
    "      for b in bills:\n",
    "        ok, bbox = b.update(frame)\n",
    "        bboxes.append(bbox)\n",
    "        if ok: draw_bbox(frame, bbox, (0, 255, 0))\n",
    "      for i, box in enumerate(bboxes):\n",
    "        for j, bo in enumerate(bboxes):\n",
    "          if (box != bo):\n",
    "            result = count_distance(box, bo)\n",
    "            if result != 0:\n",
    "              # print(result)\n",
    "              # frames_track[i] = (j, frames_number)\n",
    "              # print(result)\n",
    "              cv2.putText(frame, 'Collision', result, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "      video_tracker.write(frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "video_tracker.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -hide_banner -loglevel error -i video_tracker.avi -y video_tracker.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37261625a69f4fbb9d4abcf39f8227d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free\\x00(%\\xa9mdat\\x00\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Video.from_file('./video_tracker.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7c73bb61e1e781e5a38db13f9266bf69d55f6e669256f1cdd7a40f3a1ccea49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
