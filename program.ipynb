{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Śledzenie rozgyrwki bilarda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import niezbędnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "# import PIL\n",
    "# import os\n",
    "# import sys\n",
    "# import glob\n",
    "# import random\n",
    "\n",
    "# from pprint import pprint\n",
    "from ipywidgets import Video\n",
    "\n",
    "import PIL\n",
    "from IPython.display import display\n",
    "# from PIL.ExifTags import TAGS\n",
    "\n",
    "def imshow(a):\n",
    "  a = a.clip(0, 255).astype('uint8')\n",
    "  if a.ndim == 3:\n",
    "    if a.shape[2] == 4:\n",
    "      a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "    else:\n",
    "      a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "  display(PIL.Image.fromarray(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza wideo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie wideo i jego podstawowych właściwości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie loaded :)\n",
      "Wysokość i szerokość obrazu: 1054 x 1924\n",
      "Liczba klatek na sekundę: 59.891696750902526\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture('data/9-ball/video6.mov')\n",
    "if video.isOpened():\n",
    "    print('Movie loaded :)')\n",
    "\n",
    "width = int(video.get(3))\n",
    "height = int(video.get(4))\n",
    "print(f'Wysokość i szerokość obrazu: {height} x {width}')\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(f'Liczba klatek na sekundę: {fps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyświetlenie analizowanego wideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6e4a59836144ddbec530a04491b14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00\\x14ftypqt  \\x00\\x00\\x00\\x00qt  \\x00\\x00\\x00\\x08wide\\x01\\x02\\xee\\xc3mdat\\x00\\x01\\x03…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Video.from_file('data/9-ball/video1.mov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oddzielenie tła od ruszających się obiektów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_foreground_knn = cv2.VideoWriter('foreground_knn.avi', cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height), 0)\n",
    "video_foreground_mog2 = cv2.VideoWriter('foreground_mog2.avi', cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height), 0)\n",
    "\n",
    "foreground_knn = cv2.createBackgroundSubtractorKNN()\n",
    "foreground_mog2 = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "while video.isOpened():\n",
    "  ret, frame = video.read()\n",
    "\n",
    "  if ret:\n",
    "    video_foreground_knn.write(foreground_knn.apply(frame))\n",
    "    video_foreground_mog2.write(foreground_mog2.apply(frame))\n",
    "  else:\n",
    "    break\n",
    "\n",
    "video_foreground_knn.release()\n",
    "video_foreground_mog2.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konwersja formatów wygenerowanych wideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -hide_banner -loglevel error -i foreground_knn.avi -y foreground_knn.mp4\n",
    "!ffmpeg -hide_banner -loglevel error -i foreground_mog2.avi -y foreground_mog2.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyświetlenie wyników działania algorytmów oddzielających tło od ruszających się obiektów (maskujących tło)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Algorytm cv2.createBackgroundSubtractorKNN()')\n",
    "Video.from_file('foreground_knn.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Algorytm cv2.createBackgroundSubtractorMOG2()')\n",
    "Video.from_file('foreground_mog2.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po analizie wyników działania powyższych algorytmów do dalszej pracy wybieram algorytm KNN, który osiągnął lepszy wynik od MOG2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poszukiwanie współrzędnych bil na filmie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-066436622145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time as time\n",
    "video = cv2.VideoCapture('data/9-ball/video1.mov')\n",
    "circles = None\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Take each frame\n",
    "    _, frame = video.read()\n",
    "\n",
    "    # If video ends then break\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    blur = cv2.medianBlur(frame,5)\n",
    "    cimg = cv2.cvtColor(blur,cv2.COLOR_BGR2GRAY)\n",
    "    circles = cv2.HoughCircles(cimg,cv2.HOUGH_GRADIENT,1,20,\n",
    "                            param1=60,param2=20,minRadius=13,maxRadius=22)\n",
    "\n",
    "    circles = np.uint16(np.around(circles))\n",
    "\n",
    "    \n",
    "\n",
    "    for i in circles[0,:]:\n",
    "        # draw the outer circle\n",
    "        cv2.circle(frame,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "        # draw the center of the circle\n",
    "        cv2.circle(frame,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykorzystanie algorytmu CSRT do śledzenia znalezionych bili na filmie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tracker(tracker_type):\n",
    "  tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "\n",
    "  if tracker_type == 'BOOSTING':\n",
    "      return cv2.legacy.TrackerBoosting_create()\n",
    "  if tracker_type == 'MIL':\n",
    "      return cv2.legacy.TrackerMIL_create()\n",
    "  if tracker_type == 'KCF':\n",
    "      return cv2.legacy.TrackerKCF_create()\n",
    "  if tracker_type == 'TLD':\n",
    "      return cv2.legacy.TrackerTLD_create()\n",
    "  if tracker_type == 'MEDIANFLOW':\n",
    "      return cv2.legacy.TrackerMedianFlow_create()\n",
    "  if tracker_type == 'GOTURN':\n",
    "      return cv2.TrackerGOTURN_create()\n",
    "  if tracker_type == 'MOSSE':\n",
    "      return cv2.legacy.TrackerMOSSE_create()\n",
    "  if tracker_type == \"CSRT\":\n",
    "      return cv2.TrackerCSRT_create()\n",
    "\n",
    "def draw_bbox(frame, bbox, color=(255, 255, 255)):\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    cv2.rectangle(frame, p1, p2, color, 2, 1)\n",
    "    \n",
    "def circle_to_rectangle(circle, radius):\n",
    "    return (int(circle[0]-radius), int(circle[1]-radius), int(2*radius),  int(2*radius))\n",
    "\n",
    "def collision(c1, c2):\n",
    "    if (abs(c1[0] - c2[0])) < 40 and (abs(c1[1] - c2[1])) < 40:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def count_centroid(b):\n",
    "    return [ int(b[0] + b[2]/2), int(b[1] + b[3]/2) ]\n",
    "\n",
    "def count_distance(c1, c2):\n",
    "    clash = collision(c1, c2)\n",
    "    if clash:\n",
    "        x = (c1[0] + c2[0])/2\n",
    "        y = (c1[1] + c2[1])/2\n",
    "        return [int(x), int(y)]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie loaded :)\n",
      "Wysokość i szerokość obrazu: 1176 x 2144\n",
      "Liczba klatek na sekundę: 57.634408602150536\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture('movies/video4.mov')\n",
    "if video.isOpened():\n",
    "    print('Movie loaded :)')\n",
    "\n",
    "width = int(video.get(3))\n",
    "height = int(video.get(4))\n",
    "print(f'Wysokość i szerokość obrazu: {height} x {width}')\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(f'Liczba klatek na sekundę: {fps}')\n",
    "\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "ret, frame = video.read()\n",
    "\n",
    "# color = ('b','g','r')\n",
    "# for i,col in enumerate(color):\n",
    "#     histr = cv2.calcHist([frame],[i],None,[256],[0,256])\n",
    "#     plt.plot(histr,color = col)\n",
    "#     plt.xlim([0,256])\n",
    "# plt.show()\n",
    "\n",
    "# histr = cv2.calcHist([frame],[0],None,[256],[0,256])\n",
    "# plt.plot(histr)\n",
    "# plt.show()\n",
    "# print(np.argmax(histr))\n",
    "\n",
    "filter = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "sharpen_img_1=cv2.filter2D(frame,-1,filter)\n",
    "# imshow(sharpen_img_1)\n",
    "\n",
    "cimg = cv2.cvtColor(sharpen_img_1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "circles = cv2.HoughCircles(cimg,cv2.HOUGH_GRADIENT,1,20,\n",
    "                            param1=60,param2=20,minRadius=13,maxRadius=22)\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "max_radius = np.max(circles[0,:,2]) + 10\n",
    "\n",
    "bills = []\n",
    "count = 0\n",
    "for c in circles[0]:\n",
    "  bills.append(create_tracker('CSRT'))\n",
    "  bills[-1].init(frame, circle_to_rectangle(c, max_radius))\n",
    "\n",
    "# print(len(bills))\n",
    "\n",
    "\n",
    "for i in circles[0,:]:\n",
    "  # draw the outer circle\n",
    "  cv2.circle(frame,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "  # draw the center of the circle\n",
    "  cv2.circle(frame,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "# imshow(frame)\n",
    "\n",
    "frames_track = np.zeros((len(bills),2))\n",
    "frames_number = 0\n",
    "last_frames = np.zeros((5, len(bills), 2), dtype=np.int)\n",
    "# print(last_frames)\n",
    "# print(frames_track)\n",
    "video_tracker = cv2.VideoWriter('video_tracker_4.avi', cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height))\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if ret:\n",
    "      # bboxes = []\n",
    "      for idx, b in enumerate(bills):\n",
    "        ok, bbox = b.update(frame)\n",
    "        # bboxes.append(count_centroid(bbox))\n",
    "        # print(count_centroid(bbox))\n",
    "        last_frames[frames_number%5][idx] = count_centroid(bbox)\n",
    "        res = count_centroid(bbox)\n",
    "        cv2.putText(frame, 'ID', (res[0], res[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        if ok: draw_bbox(frame, bbox, (0, 255, 0))\n",
    "      if frames_number > 9:\n",
    "        for i, box in enumerate(last_frames[2]):\n",
    "          for j, bo in enumerate(last_frames[2]):\n",
    "            # print(i)\n",
    "            if (i != j):\n",
    "              result = count_distance(box, bo)\n",
    "              if result != 0:\n",
    "                # print(result)\n",
    "                # print(last_frames[0][i],last_frames[-1][i])\n",
    "                if ~np.array_equal(last_frames[0][i],last_frames[-1][i]):\n",
    "                  \n",
    "                  if frames_track[i][0] != j:\n",
    "                    frames_track[i] = [j, frames_number]\n",
    "                  # print(frames_track)\n",
    "                  # if (frames_track[i][0] == j and frames_number - frames_track[i][1] < 180):\n",
    "                    # print(i,j)\n",
    "                  cv2.putText(frame, 'Collision', (result[0], result[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        # print(\"sth\")\n",
    "      # print(last_frames)\n",
    "\n",
    "      video_tracker.write(frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    frames_number += 1\n",
    "\n",
    "video_tracker.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -hide_banner -loglevel error -i video_tracker_4.avi -y video_tracker_4.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc9599c3e9e4facbfd701825f4ccca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free\\x00\\x0f<\\x81mdat\\x00\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Video.from_file('./video_tracker_4.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7c73bb61e1e781e5a38db13f9266bf69d55f6e669256f1cdd7a40f3a1ccea49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
